{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quinta10/SeaBass_parsing/blob/main/Seabass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я вот тут думаю.\n",
        "начинать надо от данных\n",
        "\n",
        "1. сначала найти данные\n",
        "\n",
        "2. положение заполнить из заголовка\n",
        "\n",
        "3. а приналичии данных в fields - заменить от туда"
      ],
      "metadata": {
        "id": "g63X67iwrGEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This specific notebook works with EXPORTS data from Seabass\n",
        "\n",
        "The data is found in https://seabass.gsfc.nasa.gov/search#bio\n",
        "\n",
        "We are interested in carbon data and proxy:\n",
        "\n",
        "Chl -         Chlorophyll with its variants chla, chlb, chlc, totchl etc\n",
        "\n",
        "POC -         Particulate organic carbon and it's options\n",
        "              Note: POC_se - standard error of POC\n",
        "                    POC_sd - standard deviation of POC\n",
        "\n",
        "phyto_carbon - Carbon concentration in algae only (in vivo?)\n",
        "\n",
        "PIC  -        Particulate inorganic carbon\n",
        "\n",
        "PC   -        Particuate carbon (theoretically it is a sum of PIC and POC)\n",
        "\n",
        "_se and _sd might be in other parameters too"
      ],
      "metadata": {
        "id": "vrIwUCgHTiZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here we connect to the google drive and load libraries\n",
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "g42Cp2HoLE9v",
        "outputId": "7ea4745c-1c72-4a00-e157-dcb102307aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-19c1dd917bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mSBpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/SeabaSS/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSBpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/SeabaSS/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SBpath = '/content/drive/MyDrive/Seabass/'\n",
        "os.chdir(SBpath)\n",
        "sys.path\n",
        "\n",
        "from SB_support_extended import readSB #"
      ],
      "metadata": {
        "id": "haz1XFUAkPKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  this step adds date to the DataFrame from the 'fields' \n",
        "# we keep the previous cell in case i mess up this one and don't remember how to go back\n",
        "focus_param = ['poc','pic','pc','phyto_carbon',\n",
        "              'chl','chla','tchl','tot_chl_a']\n",
        "# focus_param = ['chl','chla','tchl','tot_chl_a']\n",
        "# coordinates\n",
        "loc_param = ['date','time',\n",
        "            'depth','pressure',\n",
        "            'lon','lat','station']\n",
        "param_methods = ['poc_m','pic_m','pc_m','phyto_c_m',\n",
        "              'chl_m','chla_m','tchl_m','tot_chl_a_m']\n",
        "\n",
        "full_list_params = ['date','time',\n",
        "            'depth','pressure',\n",
        "            'lon','lat','station',\n",
        "            'poc','pic','pc','phyto_carbon',\n",
        "              'chl','chla','tchl','tot_chl_a']\n",
        "\n",
        "\n",
        "param_short_list = set(focus_param)\n",
        "param_long_list = set(full_list_params)\n",
        "\n",
        "def SB_files_fields(P_in, param_short_list,param_long_list): # the name of the path here was messing this function\n",
        "  for root, dirs, files in os.walk(P_in, topdown=False): \n",
        "      for name in files:\n",
        "        if name.endswith('.sb'):\n",
        "          p_s = set(readSB(os.path.join(root, name),no_warn=True).headers['fields'].lower().split(','))\n",
        "          common_short_param = param_short_list.intersection(p_s)\n",
        "          if common_short_param:  # \n",
        "            file_loc = os.path.join(root, name)\n",
        "            common_long_param = param_long_list.intersection(p_s)\n",
        "            # print(common_long_param)  # \n",
        "            df_data = pd.DataFrame(readSB(file_loc,no_warn=True).data)\n",
        "            res_df = df_data[common_long_param] \n",
        "            # need to write a different function for this?\n",
        "            if 'date' not in common_long_param:\n",
        "              # how to write a df column? \n",
        "              date_in = readSB(file_loc,no_warn=True).headers['start_date']\n",
        "              # res_df['date'] = date_in # works with a warning\n",
        "              res_df = res_df.assign(date=date_in)\n",
        "            if 'time' not in common_long_param:\n",
        "              time_in = readSB(file_loc,no_warn=True).headers['start_time'][0:8]\n",
        "              res_df = res_df.assign(time=time_in) # hours/minutes ets\n",
        "            if 'lat' not in common_long_param:\n",
        "              llat_in = readSB(file_loc,no_warn=True).headers['north_latitude']\n",
        "              lat_in = re.split(r'\\[', llat_in)[0]\n",
        "              res_df = res_df.assign(lat=lat_in) # hours/minutes ets\n",
        "            if 'lon' not in common_long_param:\n",
        "              llon_in = readSB(file_loc,no_warn=True).headers['east_longitude']\n",
        "              lon_in = re.split(r'\\[', llon_in)[0]\n",
        "              res_df = res_df.assign(lon=lon_in) # hours/minutes ets\n",
        "\n",
        "\n",
        "            yield res_df, common_long_param  # \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SRW4t_UPQykC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "P_in = \"/content/drive/MyDrive/Seabass/EXPORTS/\"\n",
        "# P_in = \"/content/drive/MyDrive/Progress/Climate/Seabass/EXPORTS/MBARI/\"\n",
        "fl_list = 0\n",
        "# create an Empty DataFrame object\n",
        "df_big = pd.DataFrame()\n",
        "\n",
        "for f_n, C in SB_files_fields(P_in,param_short_list,param_long_list ):\n",
        "  df_big = df_big.append(f_n, ignore_index = True) \n",
        "  \n",
        "\n",
        "\n",
        "  df_big\n",
        "  # this works. \n",
        "  "
      ],
      "metadata": {
        "id": "hRPlGByoQyl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_big.tail()\n",
        "# 5823 x 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "mpVUvkFuQyox",
        "outputId": "b35cb953-48fc-423c-bccb-890857127885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       phyto_carbon  pressure      date      time     lat      lon  chl  \\\n",
              "25726           NaN       NaN  20180909  03:48:00  50.569 -144.543  NaN   \n",
              "25727           NaN       NaN  20180909  03:51:00  50.569 -144.543  NaN   \n",
              "25728           NaN       NaN  20180909  03:53:00  50.569 -144.543  NaN   \n",
              "25729           NaN       NaN  20180909  03:56:00  50.569 -144.543  NaN   \n",
              "25730           NaN       NaN  20180909  03:59:00  50.569 -144.543  NaN   \n",
              "\n",
              "           poc  station   depth  tchl  tot_chl_a  \n",
              "25726  27.1982    143.0  73.449   NaN        NaN  \n",
              "25727  36.4633    143.0  53.170   NaN        NaN  \n",
              "25728  56.0924    143.0  33.108   NaN        NaN  \n",
              "25729  54.1310    143.0  23.334   NaN        NaN  \n",
              "25730  52.3174    143.0  13.344   NaN        NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57033b35-610a-465b-ba64-305eb0741fc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phyto_carbon</th>\n",
              "      <th>pressure</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>chl</th>\n",
              "      <th>poc</th>\n",
              "      <th>station</th>\n",
              "      <th>depth</th>\n",
              "      <th>tchl</th>\n",
              "      <th>tot_chl_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25726</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20180909</td>\n",
              "      <td>03:48:00</td>\n",
              "      <td>50.569</td>\n",
              "      <td>-144.543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27.1982</td>\n",
              "      <td>143.0</td>\n",
              "      <td>73.449</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25727</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20180909</td>\n",
              "      <td>03:51:00</td>\n",
              "      <td>50.569</td>\n",
              "      <td>-144.543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.4633</td>\n",
              "      <td>143.0</td>\n",
              "      <td>53.170</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25728</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20180909</td>\n",
              "      <td>03:53:00</td>\n",
              "      <td>50.569</td>\n",
              "      <td>-144.543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56.0924</td>\n",
              "      <td>143.0</td>\n",
              "      <td>33.108</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25729</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20180909</td>\n",
              "      <td>03:56:00</td>\n",
              "      <td>50.569</td>\n",
              "      <td>-144.543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.1310</td>\n",
              "      <td>143.0</td>\n",
              "      <td>23.334</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25730</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20180909</td>\n",
              "      <td>03:59:00</td>\n",
              "      <td>50.569</td>\n",
              "      <td>-144.543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52.3174</td>\n",
              "      <td>143.0</td>\n",
              "      <td>13.344</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57033b35-610a-465b-ba64-305eb0741fc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57033b35-610a-465b-ba64-305eb0741fc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57033b35-610a-465b-ba64-305eb0741fc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saves a cvs file to use in excell or other software.\n",
        "# if too big - zip\n",
        "# from pathlib import Path \n",
        "# compression_opts = dict(method='zip',\n",
        "#                         archive_name='Carbon_EXPORTS.zip')   \n",
        "filepath = Path('/content/drive/MyDrive/Seabass/Carbon_EXPORTSNov22.cvs')  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df_big.to_csv(filepath) "
      ],
      "metadata": {
        "id": "pYmkxUlBM2hK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do we need to zip? "
      ],
      "metadata": {
        "id": "ax5e6KUeM2kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sand box**"
      ],
      "metadata": {
        "id": "j5102vlQrvZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По поводу того, что нужно будет сделать: \n",
        "Нужно решить проблему с тем, что в таблице могут быть разные комбинации параметров, которые относятся к дате/времени/координатам\n",
        "Для этого: \n",
        "1) Нужно написать функцию, которая будет говорить, есть ли указанный параметр в данных или нет \n",
        "\n",
        "Done\n",
        "\n",
        "\n",
        "2) На основе этой функции фильтровать исходный набор параметров, относящихся к расположению\n",
        "\n",
        "Done\n",
        "\n",
        "3) После фильтрации для параметров, которые есть в данных, взять значения из таблицы, для остальных взять значения из заголовка \n",
        "\n",
        "in progress\n",
        "\n",
        "Ещё можно подумать над тем, как изменить данные, которые мы берём из заголовков, они немного немного не в том виде\n",
        "\n",
        "regEx for the deg, "
      ],
      "metadata": {
        "id": "3x_F-iX0AtQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put the above cell in a loop?\n",
        "l_p = set(loc_param)\n",
        "\n",
        "for i in range(2):   # how many files again? How do we know? Do we need to know? 6101\n",
        "     FL = next(SB_files_fields(P_in)).lower().split(',')\n",
        "     # expectation: sets intersection() method will give us the list of common words\n",
        "     fl_set = set(FL)\n",
        "     C = l_p.intersection(fl_set)\n",
        "     print(C)\n",
        "# we see the date in the fields but in the set there is no info\n",
        "# now it works: the reason was : the function returned a string. we had to split it."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd-T7eZGbElV",
        "outputId": "ba6fb43e-d356-4dcc-f1f4-3b9ad4d267f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date,sample,bottle,lat,lon,pressure,sigma_theta,sal,wt,oxygen_kg,ratio_abs578_abs434,pH,pH_1id,pH_quality\n",
            "{'date', 'pressure', 'lat', 'lon'}\n",
            "date,sample,bottle,lat,lon,pressure,sigma_theta,sal,wt,oxygen_kg,ratio_abs578_abs434,pH,pH_1id,pH_quality\n",
            "{'date', 'pressure', 'lat', 'lon'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rlZnAE3qzts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we know the set intersection is not sufficient?\n",
        "# maybe we should no worry about it? But read all the header has?\n",
        "# and the match the two sets again. \n",
        "# mind that pressure for us is as good as depth. \n",
        "\n",
        "# i think i need a similar function to read the header"
      ],
      "metadata": {
        "id": "r5idX0PPgEtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SB_files_header(SB_path_in): # the name of the path here was messing this function\n",
        "  for root, dirs, files in os.walk(SB_path_in, topdown=False): \n",
        "      for name in files:\n",
        "        if name.endswith('.sb'):\n",
        "          header_set = readSB(os.path.join(root, name),no_warn=True).headers\n",
        "          yield header_set\n",
        "# I am using the same function that reads fields (as \n",
        "#fields are in the same header)"
      ],
      "metadata": {
        "id": "8zyQZrF6hkEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# playing with regex\n",
        "import re\n",
        "long_in = read_head['west_longitude']\n",
        "result = re.split(r'\\[', long_in)\n",
        "print(result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isgeB-xOoPeH",
        "outputId": "0a421411-b594-48bb-a9c4-45d8199c7100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-145.7563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read_head = next(SB_files_header(P_in))\n",
        "# problem 1 not every header has all the keys\n",
        "# problem 2 - get rid of the text part (reg expressions?)\n",
        "# print(read_head)\n",
        "\n",
        "print(read_head['start_date'])\n",
        "print(read_head['end_date'])\n",
        "print(read_head['start_time'][0:8]) # just cut GMT off\n",
        "print(read_head['end_time'][0:8])\n",
        "# print(read_head['station']) # not everywhere\n",
        "# i think there is no way we do not get these values. the files cannot be without these\n",
        "print(re.split(r'\\[', read_head['west_longitude'])[0])\n",
        "print(re.split(r'\\[', read_head['east_longitude'])[0])\n",
        "print(re.split(r'\\[', read_head['north_latitude'])[0])\n",
        "print(re.split(r'\\[', read_head['south_latitude'])[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ''' we need: keys: data_file_name\n",
        "#            start_date,\n",
        "#            end_date,\n",
        "#            start_time, 19:27:00[GMT]\n",
        "#            'water_depth'\n",
        "#            end_time,\n",
        "#            'station',\n",
        "#            'west_longitude', '-145.7563[DEG]',\n",
        "#            'east_longitude', '-144.4505[DEG]',\n",
        "#            'north_latitude', '51.042[DEG]', \n",
        "#            'south_latitude', '49.948[DEG]'\n",
        "#     one of the issues is that the coord are with [DEG]\n",
        "#     and the time is with [GMT]  ---> Q: is it always like that?\n",
        "#     So we pull these data out same way as we pull fields.\n",
        "#     next step we fill\n",
        "#           '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aigBkPiwhkIN",
        "outputId": "234aeb0a-2c14-42de-b156-2b08c2a69c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20180814\n",
            "20180909\n",
            "00:00:00\n",
            "23:59:59\n",
            "-145.7563\n",
            "-144.4505\n",
            "51.042\n",
            "49.948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8Q0NHwihkJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# l_p = set(loc_param)\n",
        "# print(type(l_p))\n",
        "# FL = set(next(SB_files_fields(P_in)).lower().split(','))\n",
        "# print(len(FL))"
      ],
      "metadata": {
        "id": "VWDkaaoXhkNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a test. I don't understand, why my function is stuck either at the same value or gives \"stopItteration\"\n",
        "# possible reasons: i stop itteratio by somneerting the output  to list or using a print function. \n",
        "# this simple itterator with a condition, works\n",
        "import random\n",
        "def try_gen(a,b):\n",
        "    r = random.randint(1, 8)\n",
        "    \n",
        "    if r <5 :\n",
        "      bb = r\n",
        "    else: bb = 20\n",
        "    yield bb,r"
      ],
      "metadata": {
        "id": "C9E8Spr1lsZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_list = []\n",
        "for i in range(5):\n",
        "    # for ii in try_gen(1,8):\n",
        "    s_l = next(try_gen(1,8))\n",
        "    some_list.append(s_l[1])\n",
        "\n",
        "print(some_list)\n",
        "# this works"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj5BpybPmxtZ",
        "outputId": "46107257-4090-4c55-9692-63ba391fd86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 1, 5, 7, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's compare it to the parameter list that I am interested in\n",
        "# parameters we want\n",
        "focus_param = ['poc','pic','pc','phyto_c',\n",
        "              'chl','chla','tchl','tot_chl_a']\n",
        "# coordinates\n",
        "loc_param = ['date','time',\n",
        "            'depth','pressure',\n",
        "            'lon','lat','station']\n",
        "param_methods = ['poc_m','pic_m','pc_m','phyto_c_m',\n",
        "              'chl_m','chla_m','tchl_m','tot_chl_a_m']\n",
        "#  exceptions: \n",
        "# poc_sd, poc_se, prochlorococcus, picoeukaryote, Bchl_a"
      ],
      "metadata": {
        "id": "109QwBUxK-ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if the set of the generator coinsides with carb_param - we create a dataframe and write the data\n",
        "res_df = pd.DataFrame(columns = loc_param+\n",
        "                      focus_param+\n",
        "                      param_methods)\n",
        "# res_df\n"
      ],
      "metadata": {
        "id": "gvfQ8yS3N7wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = SB_files_fields(sbPath)\n",
        "for ii in range(101):  # there are 6101 files\n",
        "    fields_from_file = next(f).split(',')\n",
        "# I need to return the actual overlaps not just yes/no. \n",
        "    # print(fields_from_file)\n",
        "    check_in = (set(focus_param) & set(fields_from_file))\n",
        "    # print(check_in)\n",
        "    if len(check_in)>0:\n",
        "      print(check_in)"
      ],
      "metadata": {
        "id": "nxzPCICTNy4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#  first take on the parameters. It might happen that chl will have to be extended to more than 1 column\n",
        "# chl, poc, phyto_carbon, pic, pc\n",
        "# paramters in the files are written with upper and lower case randomly\n",
        "param_set = {'chl', 'poc', 'phyto_carbon', 'pic', 'pc'}\n",
        "\n"
      ],
      "metadata": {
        "id": "X9pervmqVutr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SB_files_fields(SB_path_in): # the name of the path here was messing this function\n",
        "  for root, dirs, files in os.walk(SBpath, topdown=False): \n",
        "      for name in files:\n",
        "        if name.endswith('.sb'):\n",
        "          # print(os.path.join(root, name))\n",
        "          param_set = readSB(os.path.join(root, name),no_warn=True).headers['fields']\n",
        "          #      read the file           'fields' only from the header, turn to lower case cannot assign if slpit\n",
        "          print(param_set)\n",
        "          yield param_set\n",
        "\n",
        "          # what if the file doesn't read? Coding is wrong? Coding is fixed with the new support file"
      ],
      "metadata": {
        "id": "j4kjp-dsGgty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "if there is no \"date\" in this string (start_date  from  .headers) maybe it makes sense to take it from headers from the start\n",
        "\n",
        "if there is no depth, but pressure (make a note \"method\"?)\n",
        "\n",
        "if date in year mon day\n",
        "\n",
        "if time in hour minute second\n",
        "\n",
        "if lon in logitude\n",
        "\n",
        "if lat in latitude"
      ],
      "metadata": {
        "id": "u3By_6-aL6f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "ii = 0\n",
        "for root, dirs, files in os.walk(\"/gdrive/MyDrive/Progress/Climate/Seabass/EXPORTS/\", topdown=False): \n",
        "  for name in files:\n",
        "        if name.endswith('.sb'):\n",
        "          ii+=1\n",
        "print(ii)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXFNiGWvF2Dd",
        "outputId": "1595f984-4e06-485f-d060-733546b40fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6101\n"
          ]
        }
      ]
    }
  ]
}